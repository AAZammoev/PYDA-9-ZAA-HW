{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Деревья решений. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda:\n",
    "* критерий информативности с нуля\n",
    "* визуализация разделяющих поверхностей решения и визуализация самого дерева\n",
    "* оценка важности фичей\n",
    "* ужасы переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Критерий информативности с нуля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как мы разобрали, построение дерева зависит от следующих факторов:\n",
    "* вид правила разбиения\n",
    "* критерий информативности\n",
    "* критерий останова\n",
    "* метод стрижки\n",
    "* проблема пропусков\n",
    "\n",
    "пройдёмся критериям информативности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Нам понадобятся две библиотеки: numpy вы знаете, а объект класса Counter в заданном списке просто подсчитывает количество вхождений каждого элемента и возвращает результат в виде словаря. Пример:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({9: 3, 7: 2})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([9,9,9,7,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Для численного измерения улучшения разбиений на каждом этапе мы вводим некоторый *критерий информативности*, который будет оценивать разнообразие объектов в выборке: чем больше разных классов в выборке, тем больше значение H(R). Чем меньше взвешенное значение критерия после разбиения - тем лучше*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлена функция для расчёта энтропийного критерия качества:\n",
    "\n",
    "$H(R) = -\\sum_{k=1}^{K}p_klogp_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Дополните функцию расчёта энтропийного критерия множества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HEntropy(l):\n",
    "    length = len(l)\n",
    "    cnt = Counter(l)\n",
    "    \n",
    "    ent = 0\n",
    "    for cl in cnt.values():\n",
    "        p = cl / length\n",
    "        l2 = np.log2(p)\n",
    "        it = -p * l2\n",
    "        ent += it\n",
    "    \n",
    "    return ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** По аналогии с *энтропийным критерием* заполните функции *критерия Джини*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HGini(l):\n",
    "    length = len(l)\n",
    "    cnt = Counter(l)\n",
    "    \n",
    "    gini = 0\n",
    "    for cl in cnt.values():\n",
    "        p_1 = cl / length\n",
    "        p_2 = (1 - p_1)\n",
    "        it = p_1 * p_2\n",
    "        gini += it\n",
    "    \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Information Gain (IG)* - функционал качества, отвечающий на вопрос, а сколько энтропии мы погасили при определённом разбиении? На каждом шаге разбиения при построении дерева максимизируется IG. Формула для вычисления при критерии информативности H:\n",
    "\n",
    "$IG(R) = H(R) - \\frac{|R_l|}{|R|}H(R_l) - \\frac{|R_r|}{|R|}H(R_r)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Заполните функцию для вычисления функционала качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IG(H, l, i):\n",
    "    left_l = l[:i]\n",
    "    right_l = l[i:]\n",
    "    return H(l) - (len(left_l) / len(l)) * H(left_l) - (len(right_l) / len(l)) * H(right_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я подготовил функцию для визуализации работы произвольного критерия качества на выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_H(H, l):\n",
    "    print(\"{:5} {:3}   {:4} {:4} {:4}\".format(\"#\",\"l\",\"IG\",\"Hl\",\"Hr\"))\n",
    "    print(\"-\"*24)\n",
    "    for i in range(1,len(l)):\n",
    "        print(\"{:2}. {:3}   {:.2f} {:.2f} {:.2f}\".format(i, l[i], IG(H, l, i), H(l[:i]), H(l[i:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну что, определим как-нибудь выборку и посмотрим, какое разбиение предложат критерии информативности. Замечу, что элементы здесь будут выводиться начиная со второго, а значения функций рассчитаны для разбиения *перед* элементом строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "l = [1]*5 + [2]*3 + [1]*4\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#     l     IG   Hl   Hr  \n",
      "------------------------\n",
      " 1.   1   0.04 0.00 0.85\n",
      " 2.   1   0.08 0.00 0.88\n",
      " 3.   1   0.12 0.00 0.92\n",
      " 4.   1   0.17 0.00 0.95\n",
      " 5.   2   0.24 0.00 0.99\n",
      " 6.   2   0.03 0.65 0.92\n",
      " 7.   2   0.01 0.86 0.72\n",
      " 8.   1   0.17 0.95 0.00\n",
      " 9.   1   0.12 0.92 0.00\n",
      "10.   1   0.08 0.88 0.00\n",
      "11.   1   0.04 0.85 0.00\n"
     ]
    }
   ],
   "source": [
    "test_H(HEntropy, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#     l     IG   Hl   Hr  \n",
      "------------------------\n",
      " 1.   1   0.01 0.00 0.40\n",
      " 2.   1   0.02 0.00 0.42\n",
      " 3.   1   0.04 0.00 0.44\n",
      " 4.   1   0.06 0.00 0.47\n",
      " 5.   2   0.09 0.00 0.49\n",
      " 6.   2   0.01 0.28 0.44\n",
      " 7.   2   0.00 0.41 0.32\n",
      " 8.   1   0.06 0.47 0.00\n",
      " 9.   1   0.04 0.44 0.00\n",
      "10.   1   0.02 0.42 0.00\n",
      "11.   1   0.01 0.40 0.00\n"
     ]
    }
   ],
   "source": [
    "test_H(HGini, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** проверьте, какое разбиение будет сделано на втором шаге?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step_split = {}\n",
    "# for i in range(1,len(l)):\n",
    "#     step_split[i] = IG(HEntropy, l, i) \n",
    "# [key for key in step_split if step_split[key] == min(step_split.values())][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(H, l):\n",
    "    step_split = {}\n",
    "    if len(set(l)) > 1:\n",
    "        for i in range(1,len(l)):\n",
    "            step_split[i] = IG(H, l, i) \n",
    "        index_split = [key for key in step_split if step_split[key] == max(step_split.values())][0]\n",
    "        left_list, right_list = l[:index_split], l[index_split:]\n",
    "        return left_list, right_list\n",
    "    else:\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1, 1, 1, 1], [2, 2, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_split(HEntropy, l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_list, right_list = get_split(HEntropy, l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_split(HGini, left_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 2, 2], [1, 1, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_split(HEntropy, right_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Реализовал простенькую функцию для ветвления, которая учитывает остановку ветвления при подаче одинаковых значений или при отсуствии значений в строке поданной на вход. Ниже нашел и разобрал два алгоритма создания решающего дерева**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Погода Температура Влажность Ветер Гольф\n",
      "0      ясно       Жарко   Высокая   Нет     ×\n",
      "1      ясно       Жарко   Высокая  Есть     ×\n",
      "2   облачно       Жарко   Высокая   Нет     ○\n",
      "3     дождь       Тепло   Высокая   Нет     ○\n",
      "4     дождь     Холодно      Норм   Нет     ○\n",
      "5     дождь     Холодно      Норм  Есть     ×\n",
      "6   облачно     Холодно      Норм  Есть     ○\n",
      "7      ясно       Тепло   Высокая   Нет     ×\n",
      "8      ясно     Холодно      Норм   Нет     ○\n",
      "9     дождь       Тепло      Норм   Нет     ○\n",
      "10     ясно       Тепло      Норм  Есть     ○\n",
      "11  облачно       Тепло   Высокая  Есть     ○\n",
      "12  облачно       Жарко      Норм   Нет     ○\n",
      "13    дождь       Тепло   Высокая  Есть     × \n",
      "-------------\n",
      "decision tree Гольф ['×:5', '○:9']\n",
      "  Погода=дождь\n",
      "    Ветер=Есть['×:2']\n",
      "    Ветер=Нет['○:3']\n",
      "  Погода=облачно['○:4']\n",
      "  Погода=ясно\n",
      "    Влажность=Высокая['×:3']\n",
      "    Влажность=Норм['○:2']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# Дата сет\n",
    "d = {\n",
    "    \"Погода\":[\"ясно\",\"ясно\",\"облачно\",\"дождь\",\"дождь\",\"дождь\",\"облачно\",\"ясно\",\"ясно\",\"дождь\",\"ясно\",\"облачно\",\"облачно\",\"дождь\"],\n",
    "    \"Температура\":[\"Жарко\",\"Жарко\",\"Жарко\",\"Тепло\",\"Холодно\",\"Холодно\",\"Холодно\",\"Тепло\",\"Холодно\",\"Тепло\",\"Тепло\",\"Тепло\",\"Жарко\",\"Тепло\"], \n",
    "    \"Влажность\":[\"Высокая\",\"Высокая\",\"Высокая\",\"Высокая\",\"Норм\",\"Норм\",\"Норм\",\"Высокая\",\"Норм\",\"Норм\",\"Норм\",\"Высокая\",\"Норм\",\"Высокая\"],\n",
    "    \"Ветер\":[\"Нет\",\"Есть\",\"Нет\",\"Нет\",\"Нет\",\"Есть\",\"Есть\",\"Нет\",\"Нет\",\"Нет\",\"Есть\",\"Есть\",\"Нет\",\"Есть\"],\n",
    "    # Последний массив - это наша целевая переменная, показывающая результат, \n",
    "    # основывающийся на предыдущих данных.\n",
    "    \"Гольф\":[\"×\",\"×\",\"○\",\"○\",\"○\",\"×\",\"○\",\"×\",\"○\",\"○\",\"○\",\"○\",\"○\",\"×\"],\n",
    "}\n",
    "df0 = pd.DataFrame(d)\n",
    "\n",
    "# Лямбда-выражение для распределения значений, аргумент - pandas.Series, \n",
    "# возвращаемое значение - массив с количеством каждого из значений\n",
    "# Из вводных данных s с помощью value_counts() находим частоту каждого из значений, \n",
    "# и пока в нашем словаре есть элементы, будет работать цикл, запускаемый items().\n",
    "# Чтобы выходные данные не менялись с каждым запуском цикла, мы используем sorted, \n",
    "# который меняет порядок от большего к меньшему\n",
    "# В итоге, генерируется массив, содержащий строку из следующих компонентов: ключ (k) и значение (v).\n",
    "cstr = lambda s:[k+\":\"+str(v) for k,v in sorted(s.value_counts().items())]\n",
    "\n",
    "# Структура данных Decision Tree\n",
    "tree = {\n",
    "    # name: Название этого нода (узла)\n",
    "    \"name\":\"decision tree \"+df0.columns[-1]+\" \"+str(cstr(df0.iloc[:,-1])),\n",
    "    # df: Данные, связанные с этим нодом (узлом)\n",
    "    \"df\":df0,\n",
    "    # edges: Список ребер (ветвей), выходящих из этого узла, \n",
    "    # или пустой массив, если ниже нет листового узла.\n",
    "    \"edges\":[],\n",
    "}\n",
    "\n",
    "# Генерацию дерева, у узлов которого могут быть ветви, сохраняем в open\n",
    "open = [tree]\n",
    "\n",
    "# Лямба-выражение для вычесления энтропии. \n",
    "# Аргумент - pandas.Series、возвращаемое значение - число энтропии\n",
    "entropy = lambda s:-reduce(lambda x,y:x+y,map(lambda x:(x/len(s))*math.log2(x/len(s)),s.value_counts()))\n",
    "\n",
    "# Зацикливаем, пока open не станет пустым\n",
    "while(len(open)!=0):\n",
    "    # Вытаскиваем из массива open первый элемент,\n",
    "    # и вытаскиваем данные, хранящиеся в этом узле\n",
    "    n = open.pop(0)\n",
    "    df_n = n[\"df\"]\n",
    "\n",
    "    # В случае, если энтропия этого узла равна 0, мы больше не можем вырастить из него новые ветви\n",
    "    # поэтому прекращаем ветвление от этого узла\n",
    "    if 0==entropy(df_n.iloc[:,-1]):\n",
    "        continue\n",
    "    # Создаем переменную, в которую будем сохранять список значений атрибута с возможностью разветвления\n",
    "    attrs = {}\n",
    "    # Исследуем все атрибуты, кроме последнего столбца класса атрибутов\n",
    "    for attr in df_n.columns[:-1]:\n",
    "        # Создаем переменную, которая хранит значение энтропии при ветвлении с этим атрибутом,\n",
    "        # данные после разветвления и значение атрибута, который разветвляется.\n",
    "        attrs[attr] = {\"entropy\":0,\"dfs\":[],\"values\":[]}\n",
    "        # Исследуем все возможные значения этого атрибута. \n",
    "        # Кроме того, sorted предназначен для предотвращения изменения порядка массива, \n",
    "        # из которого были удалены повторяющиеся значения атрибутов, при каждом его выполнении.\n",
    "        for value in sorted(set(df_n[attr])):\n",
    "            # Фильтруем данные по значению атрибута\n",
    "            df_m = df_n.query(attr+\"=='\"+value+\"'\")\n",
    "            # Высчитываем энтропию, данные и значения сохрнаяем\n",
    "            attrs[attr][\"entropy\"] += entropy(df_m.iloc[:,-1])*df_m.shape[0]/df_n.shape[0]\n",
    "            attrs[attr][\"dfs\"] += [df_m]\n",
    "            attrs[attr][\"values\"] += [value]\n",
    "            pass\n",
    "        pass\n",
    "    # Если не осталось ни одного атрибута, значение которого можно разделить, \n",
    "    # прерываем исследование этого узла.\n",
    "    if len(attrs)==0:\n",
    "        continue\n",
    "    # Получаем атрибут с наименьшим значением энтропии\n",
    "    attr = min(attrs,key=lambda x:attrs[x][\"entropy\"])\n",
    "    # Добавляем каждое значение разветвленного атрибута\n",
    "    # и данные, полученные после разветвления, в наше дерево и в open.\n",
    "    for d,v in zip(attrs[attr][\"dfs\"],attrs[attr][\"values\"]):\n",
    "        m = {\"name\":attr+\"=\"+v,\"edges\":[],\"df\":d.drop(columns=attr)}\n",
    "        n[\"edges\"].append(m)\n",
    "        open.append(m)\n",
    "    pass\n",
    "\n",
    "# Выводим дата сет\n",
    "print(df0,\"\\n-------------\")\n",
    "# Метод преобразования дерева в символы, аргуметы - tree:структура данных древа,\n",
    "# indent:присоединяймый к дочернему узлу indent,\n",
    "# Возвращаемое значение - символьное представление древа.\n",
    "# Этот метод вызывается рекурсивно для преобразования всех данных в дереве в символы.\n",
    "def tstr(tree,indent=\"\"):\n",
    "    # Создаем символьное представление этого узла.\n",
    "    # Если этот узел является листовым узлом (количество элементов в массиве ребер равно 0), \n",
    "    # частотное распределение последнего столбца данных df, связанных с деревом, преобразуется в символы.\n",
    "    s = indent+tree[\"name\"]+str(cstr(tree[\"df\"].iloc[:,-1]) if len(tree[\"edges\"])==0 else \"\")+\"\\n\"\n",
    "    # Зацикливаем все ветви этого узла.\n",
    "    for e in tree[\"edges\"]:\n",
    "        # Добавляем символьное представление дочернего узла к символьному представлению родительского узла.\n",
    "        # Добавляем еще больше символов к indent этого узла.\n",
    "        s += tstr(e,indent+\"  \")\n",
    "        pass\n",
    "    return s\n",
    "# Выводим древо в его символьном представлении.\n",
    "print(tstr(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 < 6.642]\n",
      " [X1 < 2.771]\n",
      "  [0]\n",
      "  [X1 < 2.771]\n",
      "   [0]\n",
      "   [0]\n",
      " [X1 < 7.498]\n",
      "  [1]\n",
      "  [1]\n"
     ]
    }
   ],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "\tleft, right = list(), list()\n",
    "\tfor row in dataset:\n",
    "\t\tif row[index] < value:\n",
    "\t\t\tleft.append(row)\n",
    "\t\telse:\n",
    "\t\t\tright.append(row)\n",
    "\treturn left, right\n",
    "\n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "\t# count all samples at split point\n",
    "\tn_instances = float(sum([len(group) for group in groups]))\n",
    "\t# sum weighted Gini index for each group\n",
    "\tgini = 0.0\n",
    "\tfor group in groups:\n",
    "\t\tsize = float(len(group))\n",
    "\t\t# avoid divide by zero\n",
    "\t\tif size == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tscore = 0.0\n",
    "\t\t# score the group based on the score for each class\n",
    "\t\tfor class_val in classes:\n",
    "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
    "\t\t\tscore += p * p\n",
    "\t\t# weight the group score by its relative size\n",
    "\t\tgini += (1.0 - score) * (size / n_instances)\n",
    "\treturn gini\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "\tclass_values = list(set(row[-1] for row in dataset))\n",
    "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "\tfor index in range(len(dataset[0])-1):\n",
    "\t\tfor row in dataset:\n",
    "\t\t\tgroups = test_split(index, row[index], dataset)\n",
    "\t\t\tgini = gini_index(groups, class_values)\n",
    "\t\t\tif gini < b_score:\n",
    "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "\toutcomes = [row[-1] for row in group]\n",
    "\treturn max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "\tleft, right = node['groups']\n",
    "\tdel(node['groups'])\n",
    "\t# check for a no split\n",
    "\tif not left or not right:\n",
    "\t\tnode['left'] = node['right'] = to_terminal(left + right)\n",
    "\t\treturn\n",
    "\t# check for max depth\n",
    "\tif depth >= max_depth:\n",
    "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "\t\treturn\n",
    "\t# process left child\n",
    "\tif len(left) <= min_size:\n",
    "\t\tnode['left'] = to_terminal(left)\n",
    "\telse:\n",
    "\t\tnode['left'] = get_split(left)\n",
    "\t\tsplit(node['left'], max_depth, min_size, depth+1)\n",
    "\t# process right child\n",
    "\tif len(right) <= min_size:\n",
    "\t\tnode['right'] = to_terminal(right)\n",
    "\telse:\n",
    "\t\tnode['right'] = get_split(right)\n",
    "\t\tsplit(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "\troot = get_split(train)\n",
    "\tsplit(root, max_depth, min_size, 1)\n",
    "\treturn root\n",
    "\n",
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "\tif isinstance(node, dict):\n",
    "\t\tprint('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "\t\tprint_tree(node['left'], depth+1)\n",
    "\t\tprint_tree(node['right'], depth+1)\n",
    "\telse:\n",
    "\t\tprint('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "dataset = [[2.771244718,1.784783929,0],\n",
    "\t[1.728571309,1.169761413,0],\n",
    "\t[3.678319846,2.81281357,0],\n",
    "\t[3.961043357,2.61995032,0],\n",
    "\t[2.999208922,2.209014212,0],\n",
    "\t[7.497545867,3.162953546,1],\n",
    "\t[9.00220326,3.339047188,1],\n",
    "\t[7.444542326,0.476683375,1],\n",
    "\t[10.12493903,3.234550982,1],\n",
    "\t[6.642287351,3.319983761,1]]\n",
    "tree = build_tree(dataset, 5, 3)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
